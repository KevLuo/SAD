{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import enchant\n",
    "import datetime\n",
    "from nltk.corpus import brown\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "d = enchant.Dict(\"en_US\")\n",
    "word_set = set(brown.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET UP DATA\n",
    "\n",
    "# convert csv to a pandas DataFrame format\n",
    "train_df = pd.DataFrame.from_csv('data/train.csv')\n",
    "test_df = pd.DataFrame.from_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check misspellings\n",
    "def spell_check_sentence(sentence):\n",
    "    misspelled = [not d.check(x) if x!= \"\" else False for x in sentence.split(\" \")]\n",
    "    return sum(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    # CREATING FEATURES\n",
    "\n",
    "    #if tweet starts with quote\n",
    "    quotes = [t[0] == '\"' for t in df['text']]\n",
    "    df['in_quotes'] = quotes\n",
    "\n",
    "    #it tweet contains @realdonaldtrump\n",
    "    df['uses_own_handle'] = [\"@realDonaldTrump\" in t for t in df['text']]\n",
    "\n",
    "    #if tweet contains http\n",
    "    df['contains_http'] = [\"http\" in t for t in df['text']]\n",
    "\n",
    "    #if tweet contains hashtag\n",
    "    df['contains_hashtag'] = [\"#\" in t for t in df['text']]\n",
    "\n",
    "    #check for emojis (U+)\n",
    "    df['contains_emojis'] = [\"U+\" in t for t in df['text']]\n",
    "\n",
    "    #check length\n",
    "    df['length'] = [len(t) for t in df['text']]\n",
    "\n",
    "    #check num of mispellings\n",
    "    df['num_of_misspellings'] = [spell_check_sentence(s) for s in df['text']]\n",
    "    \n",
    "    #converting created to time of day (in seconds)\n",
    "    times = [t.split(' ')[1].split(':') for t in df['created']]\n",
    "    df['time_of_day_sec'] = [datetime.timedelta(hours = int(time[0]), minutes = int(time[1])).seconds for time in times]\n",
    "    \n",
    "    df['contains_any_at'] = ['@' in s for s in df['text']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = create_features(train_df)\n",
    "features = features.drop(['favorited', 'truncated', 'replyToSID', 'id.1', 'replyToUID', 'statusSource', 'screenName', 'isRetweet', 'retweeted','longitude', 'latitude'], axis=1)\n",
    "labels = np.array(features['label'])\n",
    "features = features.drop(['created', 'label', 'text', 'replyToSN'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "train_features, validate_features, train_labels, validate_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = XGBClassifier(max_depth=5)\n",
    "xgboost.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87155963302752293"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(xgboost.predict(validate_features) == validate_labels)/float(len(validate_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "test_features = create_features(test_df)\n",
    "test_features = test_features.drop(['favorited', 'truncated', 'replyToSID', 'id.1', 'replyToUID', 'screenName', 'isRetweet', 'retweeted','longitude', 'latitude'], axis=1)\n",
    "test_features = test_features.drop(['created', 'text', 'replyToSN'], axis = 1)\n",
    "test_features_list = list(test_features.columns)\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "ada_pred = ada.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.arange(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['Label'] = ada_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.columns = ['ID', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('ada_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
