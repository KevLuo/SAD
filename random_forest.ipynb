{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import enchant\n",
    "import datetime\n",
    "from nltk.corpus import brown\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "d = enchant.Dict(\"en_US\")\n",
    "word_set = set(brown.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET UP DATA\n",
    "\n",
    "# convert csv to a pandas DataFrame format\n",
    "train_df = pd.DataFrame.from_csv('data/train.csv')\n",
    "test_df = pd.DataFrame.from_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check misspellings\n",
    "def spell_check_sentence(sentence):\n",
    "    misspelled = [not d.check(x) if x!= \"\" else False for x in sentence.split(\" \")]\n",
    "    return sum(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    # CREATING FEATURES\n",
    "\n",
    "    #if tweet starts with quote\n",
    "    quotes = [t[0] == '\"' for t in df['text']]\n",
    "    df['in_quotes'] = quotes\n",
    "\n",
    "    #it tweet contains @realdonaldtrump\n",
    "    df['uses_own_handle'] = [\"@realDonaldTrump\" in t for t in df['text']]\n",
    "\n",
    "    #if tweet contains http\n",
    "    df['contains_http'] = [\"http\" in t for t in df['text']]\n",
    "\n",
    "    #if tweet contains hashtag\n",
    "    df['contains_hashtag'] = [\"#\" in t for t in df['text']]\n",
    "\n",
    "    #check for emojis (U+)\n",
    "    df['contains_emojis'] = [\"U+\" in t for t in df['text']]\n",
    "\n",
    "    #check length\n",
    "    df['length'] = [len(t) for t in df['text']]\n",
    "\n",
    "    #check num of mispellings\n",
    "    df['num_of_misspellings'] = [spell_check_sentence(s) for s in df['text']]\n",
    "    \n",
    "    #converting created to time of day (in seconds)\n",
    "    times = [t.split(' ')[1].split(':') for t in df['created']]\n",
    "    df['time_of_day_sec'] = [datetime.timedelta(hours = int(time[0]), minutes = int(time[1])).seconds for time in times]\n",
    "    \n",
    "    df['contains_any_at'] = ['@' in s for s in df['text']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = create_features(train_df)\n",
    "features = features.drop(['favorited', 'truncated', 'replyToSID', 'id.1', 'replyToUID', 'statusSource', 'screenName', 'isRetweet', 'retweeted','longitude', 'latitude'], axis=1)\n",
    "labels = np.array(features['label'])\n",
    "features = features.drop(['created', 'label', 'text', 'replyToSN'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "train_features, validate_features, train_labels, validate_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=1, oob_score=False, random_state=42,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMPLEMENTING RANDOM FOREST\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1, -1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1, -1,  1,\n",
       "        1, -1,  1,  1,  1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,\n",
       "        1, -1,  1,  1,  1,  1, -1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1,\n",
       "       -1,  1, -1, -1, -1,  1,  1, -1, -1,  1,  1, -1,  1,  1,  1, -1, -1,\n",
       "       -1,  1,  1, -1,  1,  1,  1, -1,  1, -1,  1, -1, -1,  1, -1,  1,  1,\n",
       "       -1, -1, -1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1, -1,  1,  1, -1,\n",
       "        1, -1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1,  1,  1, -1,  1,  1,\n",
       "       -1,  1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1,  1,  1, -1,\n",
       "       -1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1, -1, -1,  1,  1,  1, -1,\n",
       "        1, -1, -1, -1,  1,  1,  1, -1,  1, -1, -1,  1,  1,  1,  1,  1,  1,\n",
       "        1, -1, -1,  1,  1,  1,  1,  1, -1, -1,  1, -1, -1,  1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88532110091743121"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pred = rf.predict(validate_features)\n",
    "sum(rf_pred == validate_labels)/float(len(rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['favoriteCount',\n",
       " 'retweetCount',\n",
       " 'in_quotes',\n",
       " 'uses_own_handle',\n",
       " 'contains_http',\n",
       " 'contains_hashtag',\n",
       " 'contains_emojis',\n",
       " 'length',\n",
       " 'num_of_misspellings',\n",
       " 'time_of_day_sec',\n",
       " 'contains_any_at']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "test_features = create_features(test_df)\n",
    "test_features = test_features.drop(['favorited', 'truncated', 'replyToSID', 'id.1', 'replyToUID', 'screenName', 'isRetweet', 'retweeted','longitude', 'latitude'], axis=1)\n",
    "test_features = test_features.drop(['created', 'text', 'replyToSN'], axis = 1)\n",
    "test_features_list = list(test_features.columns)\n",
    "test_features = np.array(test_features)\n",
    "real_predictions = rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.arange(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['Label'] = real_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.columns = ['ID', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
