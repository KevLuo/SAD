{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import enchant\n",
    "import datetime\n",
    "from nltk.corpus import brown\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "d = enchant.Dict(\"en_US\")\n",
    "word_set = set(brown.words())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SET UP DATA\n",
    "\n",
    "# convert csv to a pandas DataFrame format\n",
    "train_df = pd.DataFrame.from_csv('data/train.csv')\n",
    "test_df = pd.DataFrame.from_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check misspellings\n",
    "def spell_check_sentence(sentence):\n",
    "    misspelled = [not d.check(x) if x!= \"\" else False for x in sentence.split(\" \")]\n",
    "    return sum(misspelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    # CREATING FEATURES\n",
    "\n",
    "    #if tweet starts with quote\n",
    "    quotes = [t[0] == '\"' for t in df['text']]\n",
    "    df['in_quotes'] = quotes\n",
    "\n",
    "    #it tweet contains @realdonaldtrump\n",
    "    df['uses_own_handle'] = [\"@realDonaldTrump\" in t for t in df['text']]\n",
    "\n",
    "    #if tweet contains http\n",
    "    df['contains_http'] = [\"http\" in t for t in df['text']]\n",
    "\n",
    "    #if tweet contains hashtag\n",
    "    df['contains_hashtag'] = [\"#\" in t for t in df['text']]\n",
    "\n",
    "    #check for emojis (U+)\n",
    "    df['contains_emojis'] = [\"U+\" in t for t in df['text']]\n",
    "\n",
    "    #check length\n",
    "    df['length'] = [len(t) for t in df['text']]\n",
    "\n",
    "    #check num of mispellings\n",
    "    df['num_of_misspellings'] = [spell_check_sentence(s) for s in df['text']]\n",
    "    \n",
    "    #converting created to time of day (in seconds)\n",
    "    times = [t.split(' ')[1].split(':') for t in df['created']]\n",
    "    df['time_of_day_sec'] = [datetime.timedelta(hours = int(time[0]), minutes = int(time[1])).seconds for time in times]\n",
    "    \n",
    "    df['contains_any_at'] = ['@' in s for s in df['text']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = create_features(train_df)\n",
    "features = features.drop(['favorited', 'truncated', 'replyToSID', 'id.1', 'replyToUID', 'statusSource', 'screenName', 'isRetweet', 'retweeted','longitude', 'latitude'], axis=1)\n",
    "labels = np.array(features['label'])\n",
    "features = features.drop(['created', 'label', 'text', 'replyToSN'], axis = 1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "\n",
    "train_features, validate_features, train_labels, validate_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=500, random_state=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "test_features = create_features(test_df)\n",
    "test_features = test_features.drop(['favorited', 'truncated', 'replyToSID', 'id.1', 'replyToUID', 'screenName', 'isRetweet', 'retweeted','longitude', 'latitude'], axis=1)\n",
    "test_features = test_features.drop(['created', 'text', 'replyToSN'], axis = 1)\n",
    "test_features_list = list(test_features.columns)\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "ada_pred = ada.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.arange(300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df['Label'] = ada_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.columns = ['ID', 'Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_df.to_csv('ada_predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
