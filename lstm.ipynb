{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLACE ALL IMPORTS IN THIS CELL\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sn446/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  after removing the cwd from sys.path.\n",
      "/home/sn446/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# SET UP DATA\n",
    "\n",
    "# convert csv to a pandas DataFrame format\n",
    "train_df = pd.DataFrame.from_csv('data/train.csv')\n",
    "test_df = pd.DataFrame.from_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1089, 17)\n",
      "(300, 15)\n"
     ]
    }
   ],
   "source": [
    "# BASIC DATASET INFORMATION\n",
    "\n",
    "# -- our train set is 1089 x 17\n",
    "print(train_df.shape)\n",
    "# -- our test set is 300 x 15 (the 2 missing columns are the label and a redundant field that resembles label)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive [Android] training points: 619\n",
      "Number of negative [iPhone] training points: 470\n",
      "Percentage of training points from Android: 0.5684113865932048\n"
     ]
    }
   ],
   "source": [
    "# FIGURE OUT LABEL DISTRIBUTION [~57% of dataset came from Android]\n",
    "\n",
    "# create dataset with only positive labels -- 619 positive labels in training set\n",
    "df_train_pos = train_df[train_df.label == 1]\n",
    "# create dataset with only negative labels -- 470 negative labels in training set\n",
    "df_train_neg = train_df[train_df.label == -1]\n",
    "print(\"Number of positive [Android] training points: \" + str(len(df_train_pos)))\n",
    "print(\"Number of negative [iPhone] training points: \" + str(len(df_train_neg)))\n",
    "print(\"Percentage of training points from Android: \" + str(len(df_train_pos)/train_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/12/16 0:56\n"
     ]
    }
   ],
   "source": [
    "# EXPLORE TIME FEATURE\n",
    "print(train_df['created'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone = 0\n",
    "http = 0\n",
    "for i in range(1089):\n",
    "    \n",
    "    if \"http\" in train_df[\"text\"][i]:\n",
    "        http += 1\n",
    "        if train_df[\"label\"][i] == -1:\n",
    "            iphone += 1\n",
    "        \n",
    "    \n",
    "print(float(iphone)/http)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "android = 0\n",
    "quote = 0\n",
    "\n",
    "for i in range(1089):\n",
    "    \n",
    "    if '\"' == train_df[\"text\"][i][0]:\n",
    "        quote += 1\n",
    "        if train_df[\"label\"][i] == 1:\n",
    "            android += 1\n",
    "\n",
    "print(float(android)/quote)\n",
    "print(android)\n",
    "print(quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.text as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frequency = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 0\n",
    "for i in range(300):\n",
    "    ws = kt.text_to_word_sequence(test_df['text'][i], filters = '\"?!-')\n",
    "    max_length = max(max_length, len(ws))\n",
    "    for w in ws:\n",
    "        if w in words_frequency.keys():\n",
    "            words_frequency[w] += 1\n",
    "        else:\n",
    "            words_frequency[w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4743\n"
     ]
    }
   ],
   "source": [
    "print(len(words_frequency.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "words[\"http\"] = 0\n",
    "\n",
    "# Remove stuffs\n",
    "for key in words_frequency.keys():\n",
    "    if \"http\" in key:\n",
    "        words[\"http\"] += words_frequency[key]\n",
    "    else:\n",
    "        words[key] = words_frequency[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4436"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(words.keys())\n",
    "idx2word = {}\n",
    "word2idx = {}\n",
    "word2idx['END TOKEN'] = 0\n",
    "idx2word[0] = 'END TOKEN'\n",
    "\n",
    "counter = 0\n",
    "for i in words.keys():\n",
    "    counter += 1\n",
    "    word2idx[i] = counter\n",
    "    idx2word[counter] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created two dictionaries **word2idx** and **idx2word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 32\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, LSTM, Dropout, TimeDistributed, Activation, Input, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocabulary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-9983f1999930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocabulary' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary, hidden_size, inputlength = max_length))\n",
    "model.add(LSTM(hidden_size, return_sequences=False))\n",
    "model.add(LSTM(hidden_size, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(vocabulary)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
